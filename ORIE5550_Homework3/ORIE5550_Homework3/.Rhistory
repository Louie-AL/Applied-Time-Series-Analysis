cat("Shape 99% CI:", CI_shape, "\n")
cat("Skewn 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(-1*ML_sstd$value / -1 * ML$value)
LR_statistic > qchisq(0.95, 1)
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
LR_statistic = 2 * log(-1*ML_sstd$value / * ML$value)
LR_statistic = 2 * log(-1*ML_sstd$value / ML$value)
LR_statistic = 2 * log(-1*ML_sstd$value / -1 * ML$value)
LR_statistic > qchisq(0.95, 1)
knitr::opts_chunk$set(echo = TRUE)
# Model 1
phi1_1 <- -0.2
phi2_1 <- 0.48
polyroot(c(1, -1 * phi1_1, -1 * phi2_1))
# Model 2
phi1_2 <- -0.2
phi2_2 <- -0.48
polyroot(c(1, -1 * phi1_2, -1 * phi2_2))
# Model 3
phi1_3 <- -1.8
phi2_3 <- -0.81
polyroot(c(1, -1 * phi1_3, -1 * phi2_3))
h <- seq(0, 20, by = 1)
# Model 1
phi1_1 <- -0.2
phi2_1 <- 0.48
ARMAacf(ar=c(phi1_1,phi2_1))
ar2_1 <- arima.sim(list(order = c(2,0,0), ar = c(phi1_1,phi2_1) ), n = 200)
theoretical_acf1 <- ((64/91)*(-5/4)^(-h) + (27/91)*(5/3)^(-h))
par(mfrow = c(1, 2))
plot(ar2_1, type="l", main="Realizations for Model 1")
acf(ar2_1, lag.max=20, ylim=c(-1, 1), main="ACF & Theoretical ACF Model1")
lines(h,  theoretical_acf1, lty="dashed", col="purple")
# re-shape for comparisson
h <- seq(1, 20, by = 1)
theoretical_acf1 <- ((64/91)*(-5/4)^(-h) + (27/91)*(5/3)^(-h))
ARMAacf_model1 <- ARMAacf(ar=c(phi1_1,phi2_1), lag.max = 20)
stopifnot(all.equal(unname(ARMAacf_model1), c(1, theoretical_acf1)))
equal_1 <- all.equal(unname(ARMAacf_model1), c(1, theoretical_acf1))
cat("Are the theoretical ACF and ARMAacf equal for Model 1? R/", equal_1)
h <- seq(0, 20, by = 1)
# Model 2
phi1_2 <- -0.2
phi2_2 <- -0.48
ARMAacf(ar=c(phi1_2,phi2_2))
ar2_2 <- arima.sim(list(order = c(2,0,0), ar = c(phi1_2,phi2_2) ), n = 200)
# solving system of equations
rho_0 = 1
rho_1 = phi1_2/(1-phi2_2)
A <- matrix(c(1, 1, 1/polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[1], 1/polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[2]), nrow = 2, byrow = TRUE)
B <- c(rho_0, rho_1)
coeff <- solve(A, B)
print(coeff)
theoretical_acf2 <- Re(coeff[1] * (polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[1])**(-h) + coeff[2] * (polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[2])**(-h))
par(mfrow = c(1, 2))
plot(ar2_2, type="l", main="Realizations for Model 2")
acf(ar2_2, lag.max=20, ylim=c(-1, 1),  main="ACF & Theoretical ACF Model2")
lines(h,  theoretical_acf2, lty="dashed", col="purple")
# re-shape for comparisson
h <- seq(1, 20, by = 1)
theoretical_acf2 <- Re(coeff[1] * (polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[1])**(-h) + coeff[2] * (polyroot(c(1, -1 * phi1_2, -1 * phi2_2))[2])**(-h))
ARMAacf_model2 <- ARMAacf(ar=c(phi1_2,phi2_2),lag.max=20)
stopifnot(all.equal(unname(ARMAacf_model2), c(1, theoretical_acf2)))
equal_2 <- all.equal(unname(ARMAacf_model2), c(1, theoretical_acf2))
cat("Are the theoretical ACF and ARMAacf equal for Model 2? R/", equal_2)
h <- seq(0, 20, by = 1)
# Model 3
phi1_3 <- -1.8
phi2_3 <- -0.81
ARMAacf(ar=c(phi1_3,phi2_3))
ar2_3 <- arima.sim(list(order = c(2,0,0), ar = c(phi1_3,phi2_3) ), n = 200)
theoretical_acf3 <- ((-10/9)^(-h) * (1+(19/181)*h))
par(mfrow = c(1, 2))
plot(ar2_3, type="l", main="Realizations Plot Model 3")
acf(ar2_3, lag.max=20, ylim=c(-1, 1), main="ACF & Theoretical ACF Model3")
lines(h,  theoretical_acf3, lty="dashed", col="purple")
# re-shape for comparisson
h <- seq(1, 20, by = 1)
theoretical_acf3 <- ((-10/9)^(-h) * (1+(19/181)*h))
ARMAacf_model3 <- ARMAacf(ar=c(phi1_3,phi2_3),lag.max=20)
stopifnot(all.equal(unname(ARMAacf_model3), c(1, theoretical_acf3)))
equal_3 <- all.equal(unname(ARMAacf_model3), c(1, theoretical_acf3))
cat("Are the theoretical ACF and ARMAacf equal for Model 3? R/", equal_3)
phi1 <-  0.7
phi2 <- -0.7 ** 2
phi3 <-  0.7 ** 3
phi4 <- -0.7 ** 4
phi5 <-  0.7 ** 5
phi6 <- -0.7 ** 6
phi7 <-  0.7 ** 7
ARMAacf(ar=c(phi1,phi2, phi3, phi4, phi5, phi6, phi7))
ar_sims <- arima.sim(list(order = c(7,0,0), ar = c(phi1,phi2, phi3, phi4, phi5, phi6, phi7) ), n = 500)
par(mfrow = c(1, 2))
plot(ar_sims, type="l")
acf(ar_sims, lag.max=20, ylim=c(-1, 1))
lines(seq(0,20),ARMAacf(ar=c(phi1,phi2, phi3, phi4, phi5, phi6, phi7),lag.max=20),lty="dashed",col="red")
lines(seq(0,20),ARMAacf(ma=c(0.7),lag.max=20),lty="dashed",col="green")
# MA(1) Model
ma_sims <- arima.sim(model= list(ma = phi1), n = 500)
par(mfrow = c(1, 2))
plot(ma_sims, type="l")
acf(ma_sims, lag.max=20, ylim=c(-1, 1))
lines(seq(0,20),ARMAacf(ar=c(phi1,phi2, phi3, phi4, phi5, phi6, phi7),lag.max=20),lty="dashed",col="red")
lines(seq(0,20),ARMAacf(ma=c(0.7),lag.max=20),lty="dashed",col="green")
# import library for auto.arima and forecast functions
#install.packages("forecast")
library(forecast)
# import library for coeftest function
#install.packages("lmtest")
library(lmtest)
file_path <- "C:\\Users\\alons\\OneDrive - Cornell University\\Cornell University\\Spring 2024\\ORIE 5550\\ORIE5550_Homework3\\sunspot.txt"
data <- read.table(file_path, header = FALSE, sep = "\t")
sunspotsTS_original = ts(data, frequency = 1)
# demean series
sunspotsTS <- sunspotsTS_original - mean(sunspotsTS_original)
par(mfrow = c(1,2))
plot.ts(sunspotsTS, main = "Sunspots time series")
acf(sunspotsTS, lag.max=20, ylim=c(-1, 1), main = "Autocorrelation function")
auto.arima(sunspotsTS,max.p=5,max.q=0,ic="aic",allowmean = FALSE) # AIC
auto.arima(sunspotsTS,max.p=5,max.q=0,ic="bic",allowmean = FALSE) # BIC
pacf(sunspotsTS, lag.max=20, ylim=c(-1, 1), main = "Partial Autocorrelation function") # PACF
arma.model <- arima(sunspotsTS, order=c(2,0,0), include.mean = FALSE, method = "ML")
summary(arma.model) #
coeftest(arma.model)# get p-values
phi1_q4 <- arma.model$coef[1]
phi2_q4 <- arma.model$coef[2]
par(mfrow = c(1,2))
acf(arma.model$residuals, lag.max=20, ylim=c(-1, 1), main = "Residuals Autocorrelation function")
pacf(arma.model$residuals, lag.max=20, ylim=c(-1, 1), main = "Residuals Partial Autocorrelation function")
# QQ plot
qqnorm(arma.model$residuals, main = "QQ-plot of the regression residuals")
qqline(arma.model$residuals, col = "red", lwd = 2)
# Shapiro-Wilks test. Ho is normality
shapiro.test(arma.model$residuals)
#Box-Ljung test
Box.test(arma.model$residuals, lag=20, type="Ljung-Box")
h = 5
arma.forecast <- predict(arma.model, h)
round(arma.forecast$pred, 3)
round(arma.forecast$se, 3)
lower <- arma.forecast$pred - (1.96 * arma.forecast$se)
upper <- arma.forecast$pred + (1.96 * arma.forecast$se)
forecasted_periods <- c(101:105)
par(mfrow = c(1,1))
plot(sunspotsTS, xlim=c(1,105), main = "Forecasts for the demeaned time series, horizon = 5")
lines(forecasted_periods, arma.forecast$pred, lwd = 2)
lines(forecasted_periods, lower, lty=2, lwd=2)
lines(forecasted_periods, upper, lty=2, lwd=2)
lower
arma.forecast
load("returns.Jan.19.2024.RData")
data <- read.csv("returns.Jan.19.2024.csv")
### Function to compute minus the log-likelihood
#install.packages("rugarch")
#install.packages("parallel")
library(rugarch)
loglik = function(theta)
{-sum(log(ddist(data$MCD,distribution="std",
mu=theta[1],sigma=theta[2],shape=theta[3])))
}
### Find the minimum of minus the log-likelihood
start = c(mean(data$MCD),sd(data$MCD),4)
ML = optim(start,loglik,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML$par
aic_q1 = -2 * ML$value + 2 * length(ML$par)
aic_q1
bic_q1 = -2 * ML$value + log(length(data$MCD)) * length(ML$par)
bic_q1
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skewn 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(ML_sstd$value / ML$value)
LR_statistic > qchisq(0.95, 1)
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
LR_statistic
LR_statistic > qchisq(0.95, 1)
load("returns.Jan.19.2024.RData")
data <- read.csv("returns.Jan.19.2024.csv")
### Function to compute minus the log-likelihood
#install.packages("rugarch")
#install.packages("parallel")
library(rugarch)
loglik = function(theta)
{-sum(log(ddist(data$MCD,distribution="std",
mu=theta[1],sigma=theta[2],shape=theta[3])))
}
### Find the minimum of minus the log-likelihood
start = c(mean(data$MCD),sd(data$MCD),4)
ML = optim(start,loglik,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML$par
aic_q1 = -2 * ML$value + 2 * length(ML$par)
aic_q1
bic_q1 = -2 * ML$value + log(length(data$MCD)) * length(ML$par)
bic_q1
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skewn 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(ML_sstd$value / ML$value)
LR_statistic
LR_statistic > qchisq(0.95, 1)
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skew 99% CI:", CI_skew, "\n")
load("returns.Jan.19.2024.RData")
data <- read.csv("returns.Jan.19.2024.csv")
### Function to compute minus the log-likelihood
#install.packages("rugarch")
#install.packages("parallel")
library(rugarch)
loglik = function(theta)
{-sum(log(ddist(data$MCD,distribution="std",
mu=theta[1],sigma=theta[2],shape=theta[3])))
}
### Find the minimum of minus the log-likelihood
start = c(mean(data$MCD),sd(data$MCD),4)
ML = optim(start,loglik,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML$par
aic_q1 = -2 * ML$value + 2 * length(ML$par)
aic_q1
bic_q1 = -2 * ML$value + log(length(data$MCD)) * length(ML$par)
bic_q1
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skew 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(ML_sstd$value / ML$value)
LR_statistic
LR_statistic > qchisq(0.95, 1)
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
p_value <- 2 * pt(abs(t_stat), df = ML$counts)
p_value
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
p_value <- 2 * pt(abs(t_stat), df = ML$counts)
p_value
t_stat
ML_sstd$par[4]
LR_statistic = 2 * log(=1 * ML_sstd$value / -1 * ML$value)
load("returns.Jan.19.2024.RData")
data <- read.csv("returns.Jan.19.2024.csv")
### Function to compute minus the log-likelihood
#install.packages("rugarch")
#install.packages("parallel")
library(rugarch)
loglik = function(theta)
{-sum(log(ddist(data$MCD,distribution="std",
mu=theta[1],sigma=theta[2],shape=theta[3])))
}
### Find the minimum of minus the log-likelihood
start = c(mean(data$MCD),sd(data$MCD),4)
ML = optim(start,loglik,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML$par
aic_q1 = -2 * ML$value + 2 * length(ML$par)
aic_q1
bic_q1 = -2 * ML$value + log(length(data$MCD)) * length(ML$par)
bic_q1
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skew 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(-1 * ML_sstd$value / -1 * ML$value)
LR_statistic
LR_statistic > qchisq(0.95, 1)
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
p_value <- 2 * pt(abs(t_stat), df = ML$counts)
p_value
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skew 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(-1 * ML_sstd$value / -1 * ML$value)
LR_statistic
LR_statistic > qchisq(0.95, 1)
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
p_value <- 2 * pt(abs(t_stat), df = ML$counts)
p_value
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
p_value <- 2 * pt(abs(t_stat), df = 1)
p_value
p_value <- 2 * pt(abs(t_stat), df = 1)
p_value
p_value <- 2 * pt(abs(t_stat), df = length(data$MCD) - 4)
p_value
t_stat <- (ML_sstd$par[4] - 1) / se_sstd[4]
t_stat
p_value <- 2 * pt(abs(t_stat), df = length(data$MCD) - 4)
p_value
load("returns.Jan.19.2024.RData")
data <- read.csv("returns.Jan.19.2024.csv")
### Function to compute minus the log-likelihood
#install.packages("rugarch")
#install.packages("parallel")
library(rugarch)
loglik = function(theta)
{-sum(log(ddist(data$MCD,distribution="std",
mu=theta[1],sigma=theta[2],shape=theta[3])))
}
### Find the minimum of minus the log-likelihood
start = c(mean(data$MCD),sd(data$MCD),4)
ML = optim(start,loglik,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML$par
aic_q1 = -2 * ML$value + 2 * length(ML$par)
aic_q1
bic_q1 = -2 * ML$value + log(length(data$MCD)) * length(ML$par)
bic_q1
loglik_sstd = function(theta)
{-sum(log(ddist(data$MCD,distribution="sstd",
mu=theta[1],sigma=theta[2],shape=theta[3], skew =theta[4])))
}
### Find the minimum of minus the log-likelihood
start_sstd = c(mean(data$MCD),sd(data$MCD), 4, 1)
ML_sstd = optim(start_sstd,loglik_sstd,method="L-BFGS-B",
lower = c(-0.1,0.001, 2.1),
upper = c(0.1,1,20),hessian=TRUE)
options(digits=3)
ML_sstd$par
aic_q2 = -2 * ML_sstd$value + 2 * length(ML_sstd$par)
aic_q2
bic_q2 = -2 * ML_sstd$value + log(length(data$MCD)) * length(ML_sstd$par)
bic_q2
se_sstd <- sqrt(diag(solve(ML_sstd$hessian)))
alpha= 0.01 ## For 99% confidence intervals
CI_mean =  ML_sstd$par[1] + c(-1,1) * se_sstd[1] * qnorm(1-alpha/2)
CI_std =   ML_sstd$par[2] + c(-1,1) * se_sstd[2] * qnorm(1-alpha/2)
CI_shape = ML_sstd$par[3] + c(-1,1) * se_sstd[3] * qnorm(1-alpha/2)
CI_skew =  ML_sstd$par[4] + c(-1,1) * se_sstd[4] * qnorm(1-alpha/2)
cat("Mean 99% CI:", CI_mean, "\n")
cat("Std 99% CI:", CI_std, "\n")
cat("Shape 99% CI:", CI_shape, "\n")
cat("Skewn 99% CI:", CI_skew, "\n")
LR_statistic = 2 * log(-1*ML_sstd$value / -1 * ML$value)
LR_statistic > qchisq(0.95, 1)
library(moments)
mean(data$MCD)
median(data$MCD)
sd(data$MCD)
skewness(data$MCD)
kurtosis(data$MCD)
ML_sstd
